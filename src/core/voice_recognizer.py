"""
è¯­éŸ³è¯†åˆ«æ ¸å¿ƒæ¨¡å—
æ”¯æŒWhisperæœ¬åœ°è¯†åˆ«å’Œå¤§æ¨¡å‹ä¼˜åŒ–
"""

import threading
import time
import numpy as np
import sounddevice as sd
import whisper
from typing import Callable, Optional
from loguru import logger
from pathlib import Path
import tempfile
import wave
import os
from collections import deque

try:
    import scipy.signal
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# å¯¼å…¥æœ¬åœ°æ ‡ç‚¹ç¬¦å·å¤„ç†å™¨
try:
    from .punctuation_processor import punctuation_processor
    LOCAL_PUNCTUATION_AVAILABLE = True
except ImportError:
    LOCAL_PUNCTUATION_AVAILABLE = False


class VoiceRecognizer:
    """è¯­éŸ³è¯†åˆ«å™¨"""
    
    def __init__(self, config):
        self.config = config
        self.model = None
        self.is_recording = False
        self.callback: Optional[Callable[[str], None]] = None
        self.recording_thread = None
        
        # éŸ³é¢‘å‚æ•°
        self.sample_rate = 16000
        self.channels = 1
        self.chunk_size = 1024
        self.max_recording_time = 30  # æœ€å¤§å½•éŸ³æ—¶é—´ï¼ˆç§’ï¼‰
        
        # éŸ³é¢‘è®¾å¤‡é…ç½®
        self.input_device_id = None
        self._setup_audio_device()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.load_model()
        
    def _setup_audio_device(self):
        """è®¾ç½®éŸ³é¢‘è®¾å¤‡"""
        try:
            # è·å–å¯ç”¨çš„è¾“å…¥è®¾å¤‡
            devices = sd.query_devices()
            input_devices = [i for i, d in enumerate(devices) if d['max_input_channels'] > 0]
            
            if not input_devices:
                logger.error("æœªæ‰¾åˆ°å¯ç”¨çš„å½•éŸ³è®¾å¤‡")
                return
                
            # å°è¯•ä½¿ç”¨é…ç½®ä¸­æŒ‡å®šçš„è®¾å¤‡
            configured_device = self.config.get('voice_recognition', 'input_device_id', fallback=None)
            if configured_device is not None:
                try:
                    configured_device = int(configured_device)
                    if configured_device in input_devices:
                        self.input_device_id = configured_device
                        logger.info(f"ä½¿ç”¨é…ç½®çš„å½•éŸ³è®¾å¤‡: {configured_device}")
                        return
                    else:
                        logger.warning(f"é…ç½®çš„è®¾å¤‡ID {configured_device} ä¸å¯ç”¨")
                except ValueError:
                    logger.warning(f"é…ç½®çš„è®¾å¤‡IDæ ¼å¼é”™è¯¯: {configured_device}")
            
            # ä½¿ç”¨é»˜è®¤è®¾å¤‡
            try:
                default_device = sd.default.device
                if isinstance(default_device, tuple):
                    default_input_device = default_device[0]
                else:
                    default_input_device = default_device
                    
                if default_input_device in input_devices:
                    self.input_device_id = default_input_device
                    logger.info(f"ä½¿ç”¨é»˜è®¤å½•éŸ³è®¾å¤‡: {default_input_device}")
                    return
            except Exception as e:
                logger.warning(f"è·å–é»˜è®¤è®¾å¤‡å¤±è´¥: {e}")
            
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„è¾“å…¥è®¾å¤‡
            self.input_device_id = input_devices[0]
            logger.info(f"ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„å½•éŸ³è®¾å¤‡: {self.input_device_id}")
            
        except Exception as e:
            logger.error(f"è®¾ç½®éŸ³é¢‘è®¾å¤‡å¤±è´¥: {e}")
            self.input_device_id = None
        
    def load_model(self):
        """åŠ è½½Whisperæ¨¡å‹"""
        try:
            # ä¼˜å…ˆä½¿ç”¨tinyæ¨¡å‹ä»¥æé«˜é€Ÿåº¦
            model_name = self.config.get('voice_recognition', 'model', fallback='tiny')
            logger.info(f"æ­£åœ¨åŠ è½½Whisperæ¨¡å‹: {model_name}")
            
            # è®¾ç½®æ¨¡å‹å­˜å‚¨è·¯å¾„åˆ°é¡¹ç›®æ ¹ç›®å½•
            project_root = Path(__file__).parent.parent.parent
            models_dir = project_root / "models"
            models_dir.mkdir(exist_ok=True)
            
            # è®¾ç½®WHISPER_CACHE_DIRç¯å¢ƒå˜é‡ï¼ˆä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡æ–¹å¼ï¼‰
            os.environ['WHISPER_CACHE_DIR'] = str(models_dir)
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆæ˜ å°„å®é™…æ–‡ä»¶åï¼‰
            model_filename_map = {
                'tiny': 'tiny.pt',
                'base': 'base.pt', 
                'small': 'small.pt',
                'medium': 'medium.pt',
                'large': 'large-v3.pt',
                'turbo': 'large-v3-turbo.pt'
            }
            
            actual_filename = model_filename_map.get(model_name, f"{model_name}.pt")
            model_path = models_dir / actual_filename
            model_exists = model_path.exists()
            
            if model_exists:
                logger.info(f"å‘ç°å·²å­˜åœ¨çš„æ¨¡å‹æ–‡ä»¶: {model_path}")
                logger.info(f"æ­£åœ¨åŠ è½½æœ¬åœ°Whisperæ¨¡å‹: {model_name}")
            else:
                logger.info(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼€å§‹ä¸‹è½½åˆ°: {models_dir}")
                logger.info(f"æ­£åœ¨ä¸‹è½½Whisperæ¨¡å‹: {model_name} (çº¦800MBï¼Œè¯·ç¨å€™...)")
            
            # åŠ è½½æ¨¡å‹ï¼ˆä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼Œé¿å…é‡å¤ä¸‹è½½ï¼‰
            if model_exists:
                # ç›´æ¥ä»æœ¬åœ°æ–‡ä»¶åŠ è½½ï¼Œé¿å…ç½‘ç»œæ£€æŸ¥
                self.model = whisper.load_model(str(model_path))
            else:
                # ä½¿ç”¨download_rootå‚æ•°ç¡®ä¿ä¸‹è½½åˆ°æŒ‡å®šç›®å½•
                self.model = whisper.load_model(model_name, download_root=str(models_dir))
            
            if model_exists:
                logger.info(f"âœ… æœ¬åœ°Whisperæ¨¡å‹åŠ è½½æˆåŠŸ: {model_name}")
            else:
                logger.info(f"âœ… Whisperæ¨¡å‹ä¸‹è½½å¹¶åŠ è½½æˆåŠŸ: {model_name}")
                logger.info(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {models_dir}")
            
        except Exception as e:
            logger.error(f"åŠ è½½Whisperæ¨¡å‹å¤±è´¥: {e}")
            raise
            
    def set_callback(self, callback: Callable[[str], None]):
        """è®¾ç½®è¯†åˆ«ç»“æœå›è°ƒå‡½æ•°"""
        self.callback = callback
        
    def start_recognition(self):
        """å¼€å§‹è¯­éŸ³è¯†åˆ«"""
        if self.is_recording:
            logger.warning("æ­£åœ¨å½•éŸ³ä¸­ï¼Œå¿½ç•¥æ–°çš„è¯†åˆ«è¯·æ±‚")
            return
            
        self.is_recording = True
        self.recording_thread = threading.Thread(target=self._record_and_recognize)
        self.recording_thread.daemon = True
        self.recording_thread.start()
        
    def stop_recognition(self):
        """åœæ­¢è¯­éŸ³è¯†åˆ«"""
        self.is_recording = False
        if self.recording_thread and self.recording_thread.is_alive():
            self.recording_thread.join(timeout=1)
            
    def _record_and_recognize(self):
        """å½•éŸ³å¹¶è¯†åˆ«"""
        try:
            logger.info("å¼€å§‹å½•éŸ³...")
            
            # æ£€æŸ¥éŸ³é¢‘è®¾å¤‡
            if self.input_device_id is None:
                logger.error("æœªé…ç½®å¯ç”¨çš„å½•éŸ³è®¾å¤‡")
                return
            
            # å½•éŸ³å‚æ•°
            duration = self.config.get('voice_recognition', 'duration', fallback=5)
            
            # å½•éŸ³
            audio_data = sd.rec(
                int(duration * self.sample_rate),
                samplerate=self.sample_rate,
                channels=self.channels,
                dtype=np.float32,
                device=self.input_device_id
            )
            
            # ç­‰å¾…å½•éŸ³å®Œæˆ
            sd.wait()
            
            if not self.is_recording:
                return
                
            logger.info("å½•éŸ³å®Œæˆï¼Œå¼€å§‹è¯†åˆ«...")
            
            # è¯­éŸ³è¯†åˆ«
            text = self._recognize_audio(audio_data.flatten())
            
            if text and self.callback:
                # å¯é€‰ï¼šä½¿ç”¨å¤§æ¨¡å‹ä¼˜åŒ–æ–‡æœ¬
                if self.config.get('llm_optimization', 'enabled', fallback=False):
                    text = self._optimize_text_with_llm(text)
                    
                self.callback(text)
                
        except Exception as e:
            logger.error(f"è¯­éŸ³è¯†åˆ«è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            self.is_recording = False
            
    def _recognize_audio(self, audio_data: np.ndarray) -> str:
        """è¯†åˆ«éŸ³é¢‘æ•°æ®"""
        try:
            # å¿«é€ŸéŸ³é¢‘é¢„å¤„ç†
            audio_data = self._preprocess_audio_fast(audio_data)
            
            # ä½¿ç”¨Whisperè¿›è¡Œè¯†åˆ«ï¼Œä¼˜åŒ–å‚æ•°æé«˜é€Ÿåº¦
            result = self.model.transcribe(
                audio_data,
                language='zh',  # ä¸­æ–‡
                task='transcribe',
                temperature=0.0,  # é™ä½éšæœºæ€§
                compression_ratio_threshold=2.0,  # è¾ƒä½çš„å‹ç¼©æ¯”é˜ˆå€¼
                logprob_threshold=-0.8,  # è¾ƒä½çš„æ¦‚ç‡é˜ˆå€¼
                no_speech_threshold=0.3,  # è¾ƒä½çš„æ— è¯­éŸ³é˜ˆå€¼
                fp16=False,  # ç¦ç”¨FP16ä»¥é¿å…æŸäº›è®¾å¤‡çš„å…¼å®¹æ€§é—®é¢˜
                beam_size=1,  # ä½¿ç”¨è´ªå¿ƒæœç´¢æé«˜é€Ÿåº¦
                best_of=1,  # åªç”Ÿæˆä¸€ä¸ªå€™é€‰
                condition_on_previous_text=False,  # ä¸ä¾èµ–ä¹‹å‰çš„æ–‡æœ¬
                word_timestamps=False  # ä¸ç”Ÿæˆè¯çº§æ—¶é—´æˆ³
            )
            
            text = result.get('text', '').strip()
            
            if text:
                logger.info(f"è¯†åˆ«ç»“æœ: {text}")
                return text
            else:
                logger.warning("æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ–‡æœ¬")
                return ""
                
        except Exception as e:
            logger.error(f"éŸ³é¢‘è¯†åˆ«å¤±è´¥: {e}")
            return ""
            
    def _preprocess_audio_fast(self, audio_data: np.ndarray) -> np.ndarray:
        """å¿«é€ŸéŸ³é¢‘é¢„å¤„ç†ï¼Œå‡å°‘å»¶è¿Ÿ"""
        
        # æ£€æŸ¥éŸ³é¢‘æœ‰æ•ˆæ€§
        if len(audio_data) == 0 or np.all(audio_data == 0):
            logger.warning("éŸ³é¢‘æ•°æ®ä¸ºç©ºæˆ–å…¨é›¶")
            return np.zeros(self.sample_rate, dtype=np.float32)  # è¿”å›1ç§’çš„é™éŸ³
        
        # å»é™¤ç›´æµåˆ†é‡
        audio_data = audio_data - audio_data.mean()
        
        # æ£€æŸ¥éŸ³é¢‘è´¨é‡
        rms = np.sqrt(np.mean(audio_data ** 2))
        max_amplitude = np.max(np.abs(audio_data))
        
        logger.debug(f"éŸ³é¢‘é¢„å¤„ç† - RMS: {rms:.4f}, Max: {max_amplitude:.4f}, é•¿åº¦: {len(audio_data)/self.sample_rate:.2f}ç§’")
        
        # å½’ä¸€åŒ–
        if max_amplitude > 0:
            audio_data = audio_data * (0.6 / max_amplitude)
        
        # ç®€å•çš„å™ªå£°æ£€æµ‹
        if rms < 0.001:
            logger.warning(f"éŸ³é¢‘èƒ½é‡è¿‡ä½ (RMS: {rms:.6f})ï¼Œå¯èƒ½æ˜¯é™éŸ³æˆ–éŸ³é‡å¤ªå°")
        
        # ç¡®ä¿æ•°æ®ç±»å‹ä¸ºfloat32
        audio_data = audio_data.astype(np.float32)
        
        return audio_data

    def _optimize_text_with_llm(self, text: str) -> str:
        """ä½¿ç”¨å¤§æ¨¡å‹ä¼˜åŒ–æ–‡æœ¬"""
        if not OPENAI_AVAILABLE:
            logger.warning("OpenAIåº“ä¸å¯ç”¨ï¼Œè·³è¿‡å¤§æ¨¡å‹ä¼˜åŒ–")
            return text
            
        try:
            api_key = self.config.get('llm_optimization', 'openai_api_key', fallback='')
            if not api_key:
                logger.warning("æœªé…ç½®OpenAI API Keyï¼Œè·³è¿‡å¤§æ¨¡å‹ä¼˜åŒ–")
                return text
                
            client = openai.OpenAI(api_key=api_key)
            
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡è¯­éŸ³è¯†åˆ«æ–‡æœ¬ä¼˜åŒ–åŠ©æ‰‹ã€‚è¯·å¯¹ç”¨æˆ·çš„è¯­éŸ³è¯†åˆ«æ–‡æœ¬è¿›è¡Œä¼˜åŒ–ï¼ŒåŒ…æ‹¬ï¼š
1. çº æ­£è¯­éŸ³è¯†åˆ«é”™è¯¯ï¼ˆåŒéŸ³å­—ã€è¿‘éŸ³å­—é”™è¯¯ï¼‰
2. æ·»åŠ åˆé€‚çš„æ ‡ç‚¹ç¬¦å·
3. è§„èŒƒåŒ–è¡¨è¾¾ï¼ˆå£è¯­è½¬ä¹¦é¢è¯­ï¼‰
4. å¤„ç†æ•°å­—å’Œä¸“ä¸šæœ¯è¯­
5. ä¿æŒåŸæ„ä¸å˜

æ³¨æ„ï¼š
- ä¼˜å…ˆè€ƒè™‘ä¸­æ–‡è¯­å¢ƒå’Œä¹ æƒ¯è¡¨è¾¾
- å¦‚æœåŸæ–‡æœ¬è¿‡äºæ¨¡ç³Šæˆ–é”™è¯¯ï¼Œä¿æŒåŸæ ·
- åªè¿”å›ä¼˜åŒ–åçš„æ–‡æœ¬ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ ‡è®°"""
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                temperature=0.3,
                max_tokens=200
            )
            
            optimized_text = response.choices[0].message.content.strip()
            logger.info(f"å¤§æ¨¡å‹ä¼˜åŒ–å: {optimized_text}")
            return optimized_text
            
        except Exception as e:
            logger.error(f"å¤§æ¨¡å‹ä¼˜åŒ–å¤±è´¥: {e}")
            return text
    
    def _add_local_punctuation(self, text: str) -> str:
        """ä½¿ç”¨æœ¬åœ°å¤„ç†å™¨æ·»åŠ æ ‡ç‚¹ç¬¦å·"""
        try:
            original_text = text
            processed_text = punctuation_processor.process(text)
            
            if processed_text != original_text:
                logger.info(f"æœ¬åœ°æ ‡ç‚¹å¤„ç†: {original_text} â†’ {processed_text}")
            else:
                logger.debug(f"æœ¬åœ°æ ‡ç‚¹å¤„ç†: æ–‡æœ¬æ— å˜åŒ–")
                
            return processed_text
            
        except Exception as e:
            logger.error(f"æœ¬åœ°æ ‡ç‚¹å¤„ç†å¤±è´¥: {e}")
            return text
            
    def stop(self):
        """åœæ­¢è¯­éŸ³è¯†åˆ«å™¨"""
        self.stop_recognition()
        logger.info("è¯­éŸ³è¯†åˆ«å™¨å·²åœæ­¢")


class ContinuousVoiceRecognizer(VoiceRecognizer):
    """è¿ç»­è¯­éŸ³è¯†åˆ«å™¨ - åŸºäºå·¥ä½œæ­£å¸¸çš„åŸºç¡€è¯†åˆ«å™¨æ”¹è¿›"""
    
    def __init__(self, config):
        super().__init__(config)
        # ä¿å­˜é…ç½®å¼•ç”¨ä»¥ä¾¿çƒ­é‡è½½
        self.config = config
        self._load_continuous_params()
        
        # çŠ¶æ€å˜é‡
        self.is_monitoring = False
        self.is_auto_recording = False
        self.last_activity_time = 0
        self.debug_counter = 0
        
    def _load_continuous_params(self):
        """åŠ è½½è¿ç»­è¯†åˆ«å‚æ•°"""
        self.vad_threshold = float(self.config.get('voice_recognition', 'vad_threshold', fallback=0.020))
        self.auto_recording_duration = float(self.config.get('voice_recognition', 'auto_recording_duration', fallback=2.5))
        self.cooldown_time = float(self.config.get('voice_recognition', 'cooldown_time', fallback=0.3))
        
        # åŠ¨æ€å½•éŸ³å‚æ•°
        self.dynamic_recording = self.config.get('voice_recognition', 'dynamic_recording', fallback=True)
        self.min_recording_duration = 0.5  # æœ€å°å½•éŸ³æ—¶é•¿
        self.max_recording_duration = min(self.auto_recording_duration, 10.0)  # æœ€å¤§å½•éŸ³æ—¶é•¿
        self.silence_duration_to_stop = 0.8  # é™éŸ³å¤šä¹…ååœæ­¢å½•éŸ³
        
        logger.info(f"è¿ç»­è¯†åˆ«å‚æ•° - VADé˜ˆå€¼: {self.vad_threshold:.3f}, åŠ¨æ€å½•éŸ³: {self.dynamic_recording}")
        if self.dynamic_recording:
            logger.info(f"æ™ºèƒ½åŠ¨æ€å½•éŸ³ - èŒƒå›´: {self.min_recording_duration}-{self.max_recording_duration}ç§’, é™éŸ³åœæ­¢: {self.silence_duration_to_stop}ç§’")
        else:
            logger.info(f"å›ºå®šæ—¶é•¿å½•éŸ³ - æ—¶é•¿: {self.auto_recording_duration}ç§’")
        
    def reload_config(self):
        """é‡æ–°åŠ è½½é…ç½®å‚æ•°"""
        logger.info("é‡æ–°åŠ è½½è¿ç»­è¯†åˆ«é…ç½®...")
        self._load_continuous_params()
        logger.info("é…ç½®é‡è½½å®Œæˆ")
        
    def start_continuous_recognition(self):
        """å¼€å§‹è¿ç»­ç›‘å¬æ¨¡å¼"""
        if self.is_monitoring:
            logger.warning("è¿ç»­ç›‘å¬å·²åœ¨è¿è¡Œä¸­")
            return
            
        self.is_monitoring = True
        self.recording_thread = threading.Thread(target=self._continuous_monitor)
        self.recording_thread.daemon = True
        self.recording_thread.start()
        logger.info("âœ… è¿ç»­è¯­éŸ³ç›‘å¬å·²å¯åŠ¨")
        
    def stop_recognition(self):
        """åœæ­¢è¿ç»­ç›‘å¬"""
        self.is_monitoring = False
        self.is_auto_recording = False
        if self.recording_thread and self.recording_thread.is_alive():
            self.recording_thread.join(timeout=1)
        logger.info("è¿ç»­è¯­éŸ³ç›‘å¬å·²åœæ­¢")
        
    def _continuous_monitor(self):
        """è¿ç»­ç›‘å¬æ¨¡å¼"""
        chunk_size = 1024
        sample_rate = self.sample_rate
        
        def audio_callback(indata, frames, time, status):
            if status:
                return
                
            # è®¡ç®—éŸ³é¢‘èƒ½é‡
            audio_chunk = indata[:, 0]
            energy = np.sqrt(np.mean(audio_chunk ** 2))
            
            # å®šæœŸæ˜¾ç¤ºç›‘å¬çŠ¶æ€
            self.debug_counter += 1
            if self.debug_counter % 100 == 0:  # æ¯100ä¸ªchunkæ˜¾ç¤ºä¸€æ¬¡
                logger.debug(f"ç›‘å¬ä¸­... å½“å‰èƒ½é‡: {energy:.4f}, é˜ˆå€¼: {self.vad_threshold:.4f}")
            
            # æ£€æµ‹è¯­éŸ³æ´»åŠ¨
            if energy > self.vad_threshold:
                self.last_activity_time = time.inputBufferAdcTime
                
                # å¦‚æœæ£€æµ‹åˆ°è¯­éŸ³ä¸”å½“å‰æ²¡æœ‰å½•éŸ³ï¼Œå¼€å§‹å½•éŸ³
                if not self.is_auto_recording and not self.is_recording:
                    self.is_auto_recording = True
                    logger.info(f"ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³ (èƒ½é‡: {energy:.4f})ï¼Œå¼€å§‹å½•éŸ³...")
                    
                    # åœ¨æ–°çº¿ç¨‹ä¸­å¼€å§‹å½•éŸ³è¯†åˆ«
                    threading.Thread(
                        target=self._auto_record_and_recognize,
                        daemon=True
                    ).start()
                    
        try:
            with sd.InputStream(
                callback=audio_callback,
                samplerate=sample_rate,
                channels=1,
                dtype=np.float32,
                device=self.input_device_id,
                blocksize=chunk_size
            ):
                while self.is_monitoring:
                    time.sleep(0.1)
                    
        except Exception as e:
            logger.error(f"è¿ç»­ç›‘å¬å‡ºé”™: {e}")
        finally:
            self.is_monitoring = False
            
    def _auto_record_and_recognize(self):
        """æ™ºèƒ½åŠ¨æ€å½•éŸ³å¹¶è¯†åˆ«"""
        try:
            # æ£€æŸ¥éŸ³é¢‘è®¾å¤‡
            if self.input_device_id is None:
                logger.error("æœªé…ç½®å¯ç”¨çš„å½•éŸ³è®¾å¤‡")
                return
            
            if self.dynamic_recording:
                # ä½¿ç”¨åŠ¨æ€å½•éŸ³
                audio_data = self._dynamic_record()
            else:
                # ä½¿ç”¨å›ºå®šæ—¶é•¿å½•éŸ³ï¼ˆå‘åå…¼å®¹ï¼‰
                audio_data = self._fixed_duration_record()
            
            if audio_data is None or len(audio_data) == 0:
                logger.warning("å½•éŸ³æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡è¯†åˆ«")
                return
                
            if not self.is_monitoring:
                return
                
            logger.info("âš¡ å½•éŸ³å®Œæˆï¼Œå¼€å§‹è¯†åˆ«...")
            
            # è¯­éŸ³è¯†åˆ«
            text = self._recognize_audio(audio_data)
            
            if text and self.callback:
                # æ–‡æœ¬ä¼˜åŒ–ï¼šå¤§æ¨¡å‹ > æœ¬åœ°æ ‡ç‚¹å¤„ç†å™¨ > åŸå§‹æ–‡æœ¬
                if self.config.get('llm_optimization', 'enabled', fallback=False):
                    text = self._optimize_text_with_llm(text)
                elif LOCAL_PUNCTUATION_AVAILABLE:
                    text = self._add_local_punctuation(text)
                    
                self.callback(text)
                
        except Exception as e:
            logger.error(f"è‡ªåŠ¨å½•éŸ³è¯†åˆ«è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            self.is_auto_recording = False
            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´å†å…è®¸ä¸‹æ¬¡å½•éŸ³
            time.sleep(self.cooldown_time)
    
    def _dynamic_record(self):
        """åŠ¨æ€æ—¶é•¿å½•éŸ³ï¼šæ ¹æ®è¯­éŸ³æ´»åŠ¨è‡ªåŠ¨ç¡®å®šå½•éŸ³é•¿åº¦"""
        logger.info("ğŸ™ï¸ å¼€å§‹åŠ¨æ€å½•éŸ³...")
        
        # å½•éŸ³ç¼“å†²åŒº
        audio_buffer = []
        chunk_size = 1024
        chunk_duration = chunk_size / self.sample_rate
        
        # çŠ¶æ€å˜é‡
        recording_time = 0.0
        silence_time = 0.0
        
        try:
            with sd.InputStream(
                samplerate=self.sample_rate,
                channels=self.channels,
                dtype=np.float32,
                device=self.input_device_id,
                blocksize=chunk_size
            ) as stream:
                
                while recording_time < self.max_recording_duration and self.is_monitoring:
                    # è¯»å–éŸ³é¢‘å—
                    audio_chunk, overflowed = stream.read(chunk_size)
                    if overflowed:
                        logger.debug("éŸ³é¢‘ç¼“å†²åŒºæº¢å‡º")
                    
                    # æ·»åŠ åˆ°ç¼“å†²åŒº
                    audio_buffer.append(audio_chunk.flatten())
                    recording_time += chunk_duration
                    
                    # è®¡ç®—å½“å‰å—çš„èƒ½é‡
                    energy = np.sqrt(np.mean(audio_chunk.flatten() ** 2))
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºé™éŸ³
                    if energy < self.vad_threshold * 0.3:  # é™éŸ³é˜ˆå€¼æ›´ä¸¥æ ¼
                        silence_time += chunk_duration
                    else:
                        silence_time = 0.0  # é‡ç½®é™éŸ³è®¡æ—¶
                    
                    # æå‰åœæ­¢æ¡ä»¶
                    if (recording_time >= self.min_recording_duration and 
                        silence_time >= self.silence_duration_to_stop):
                        logger.info(f"ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³ {silence_time:.1f}ç§’ï¼Œæå‰ç»“æŸå½•éŸ³")
                        break
                        
                    # æ¯0.5ç§’æ˜¾ç¤ºä¸€æ¬¡çŠ¶æ€
                    if int(recording_time * 2) != int((recording_time - chunk_duration) * 2):
                        logger.debug(f"å½•éŸ³ä¸­... {recording_time:.1f}s, èƒ½é‡: {energy:.4f}, é™éŸ³: {silence_time:.1f}s")
        
        except Exception as e:
            logger.error(f"åŠ¨æ€å½•éŸ³è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return None
        
        # åˆå¹¶éŸ³é¢‘æ•°æ®
        if audio_buffer:
            audio_data = np.concatenate(audio_buffer)
            logger.info(f"âœ… åŠ¨æ€å½•éŸ³å®Œæˆï¼Œå®é™…æ—¶é•¿: {recording_time:.1f}ç§’")
            return audio_data
        else:
            logger.warning("å½•éŸ³ç¼“å†²åŒºä¸ºç©º")
            return None
    
    def _fixed_duration_record(self):
        """å›ºå®šæ—¶é•¿å½•éŸ³ï¼šå‘åå…¼å®¹çš„å½•éŸ³æ–¹å¼"""
        duration_samples = int(self.auto_recording_duration * self.sample_rate)
        logger.debug(f"å›ºå®šå½•éŸ³ - æ—¶é•¿: {self.auto_recording_duration}ç§’, æ ·æœ¬æ•°: {duration_samples}")
        
        audio_data = sd.rec(
            duration_samples,
            samplerate=self.sample_rate,
            channels=self.channels,
            dtype=np.float32,
            device=self.input_device_id
        )
        
        # ç­‰å¾…å½•éŸ³å®Œæˆ
        sd.wait()
        return audio_data.flatten() 